<!DOCTYPE HTML><html lang="zh-ch"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><title>Xu Tang&#39;s Homepages</title><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="author" content="Xu Tang&#39;s Homepages"><meta name="description" content="Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking"><meta property="og:type" content="website"><meta property="og:title" content="Xu Tang&#39;s Homepages"><meta property="og:url" content="http://tangxuvis.github.io/index.html"><meta property="og:site_name" content="Xu Tang&#39;s Homepages"><meta property="og:description" content="Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking"><meta property="og:locale" content="zh-ch"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Xu Tang&#39;s Homepages"><meta name="twitter:description" content="Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking"><link rel="alternative" href="/atom.xml" title="Xu Tang&#39;s Homepages" type="application/atom+xml"><link rel="icon" href="/img/favicon-32x32.ico"><link rel="apple-touch-icon" href="/img/jacman.jpg"><link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg"><link rel="stylesheet" href="/css/style.css"></head></html><body><header><div><div id="imglogo"><a href="/"><img src="/img/logo.png" alt="Xu Tang&#39;s Homepages" title="Xu Tang&#39;s Homepages"></a></div><div id="textlogo"><h1 class="site-name"><a href="/" title="Xu Tang&#39;s Homepages">Xu Tang&#39;s Homepages</a></h1><h2 class="blog-motto">Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking</h2></div><div class="navbar"><a class="navbutton navmobile" href="#" title="Menu"></a></div><nav class="animated"><ul><ul><li><a href="/">Home</a></li><li><a href="/archives">Archives</a></li><li><a href="/tags">Tags</a></li><li><a href="/resume">Resume</a></li><li><a href="/recruit">Recruit</a></li><li><a href="/about">About</a></li><li><form class="search" action="//google.com/search" method="get" accept-charset="utf-8"><label>Search</label> <input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search"> <input type="hidden" name="q" value="site:tangxuvis.github.io"></form></li></ul></ul></nav></div></header><div id="container"><div id="main"><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2020/04/25/One-tech-talk/" title="One tech talk" itemprop="url">One tech talk</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2020-04-25T15:19:43.000Z" itemprop="datePublished">Published 2020-04-25</time></p></header><div class="article-content"><p>Someone share the video on youtube, please see details here.<br><a href="https://www.youtube.com/watch?reload=9&amp;v=kA9FWQjjU_4&amp;list=PLiG8_90geV" target="_blank" rel="noopener">https://www.youtube.com/watch?reload=9&amp;v=kA9FWQjjU_4&amp;list=PLiG8_90geV</a><br><a href="https://www.youtube.com/watch?v=FXC0b9yNOX0" target="_blank" rel="noopener">https://www.youtube.com/watch?v=FXC0b9yNOX0</a></p><p align="center"><img src="/imgs/iccv2019_workshop_ppt/talk_video.jpg" hspace="10"><br></p><p class="article-more-link"><a href="/2020/04/25/One-tech-talk/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2020/04/21/history_of_face_detection/" title="人脸检测技术发展及百度“框”实践" itemprop="url">人脸检测技术发展及百度“框”实践</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2020-04-21T08:34:41.000Z" itemprop="datePublished">Published 2020-04-21</time></p></header><div class="article-content"><p>撰文<a href="https://www.jiqizhixin.com/articles/2020-04-17-4?from=timeline&isappinstalled=0" target="_blank" rel="noopener">《人脸检测技术发展及百度“框”实践》</a>，发表在机器之心栏目。</p><p align="center"><img src="/imgs/cvpr2020/history.jpg" height="400" width="600" hspace="10"><br></p><p align="center"><img src="/imgs/cvpr2020/introduction.jpg" height="400" width="600" hspace="10"><br></p><p class="article-more-link"><a href="/2020/04/21/history_of_face_detection/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2020/04/21/cvpr2020_hambox_bfbox/" title="News:2 papers accepted by CVPR2020" itemprop="url">News:2 papers accepted by CVPR2020</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2020-04-21T08:25:04.000Z" itemprop="datePublished">Published 2020-04-21</time></p></header><div class="article-content"><p><a href="https://arxiv.org/abs/1912.09231" target="_blank" rel="noopener">HAMBox: Delving into Online High-quality Anchors Mining for Detecting Outer Faces</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Current face detectors utilize anchors to frame a multi-task learning problem which combines classification and bounding box regression. Effective anchor design and anchor matching strategy enable face detectors to localize faces under large pose and scale variations. However, we observe that more than 80% correctly predicted bounding boxes are regressed from the unmatched anchors (the IoUs between anchors and target faces are lower than a threshold) in the inference phase. It indicates that these unmatched anchors perform excellent regression ability, but the existing methods neglect to learn from them. In this paper, we propose an Online High-quality Anchor Mining Strategy (HAMBox), which explicitly helps outer faces compensate with high-quality anchors. Our proposed HAMBox method could be a general strategy for anchor-based single-stage face detection. Experiments on various datasets, including WIDER FACE, FDDB, AFW and PASCAL Face, demonstrate the superiority of the proposed method. Furthermore, our team win the championship on the Face Detection test track of WIDER Face and Pedestrian Challenge 2019. We will release the codes with PaddlePaddle.</p><p align="center"><img src="/imgs/cvpr2020/cvpr2020_hambox.jpg" height="400" width="600" hspace="10"><br></p><p>BFBox: Searching Face-appropriate Backbone and Feature Pyramid Network for Robust Face Detector</p><h2 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文提出的方法BFBox是基于神经网络架构搜索（NAS）的方法同时搜索适合人脸检测的特征提取器和特征金字塔。动机是我们发现了一个有趣的现象：针对图像分类任务设计的流行的特征提取器已经在通用目标检测任务上验证了其重要的兼容性，然而在人脸检测任务上却没有取得预期的效果。同时不同的特征提取器与特征金字塔的结合也不是完全正相关的。首先，本文对于比较好的特征提取器进行分析，提出了适合人脸的搜索空间；其次，提出了图1的特征金字塔注意力模块（FPN-attention Module）去加强特征提取器和特征金字塔之间的联系；最后, 采取SNAS的方法同时搜出适和人脸的特征提取器和特征金字塔结构。多个数据集上（WIDER FACE, FDDB, AFW和PASCAL Face）的实验表明了我们提出的方法的优越性。<br>如下图所示为检测网络的结构。网络是基于RetinaNet的结构加上我们提出的特征金字塔注意力模块（FPN-attention Module），训练超网络时采用的是随机采样的方法。</p><p align="center"><img src="/imgs/cvpr2020/cvpr2020_bfbox.jpg" height="400" width="600" hspace="10"><br></p><p class="article-more-link"><a href="/2020/04/21/cvpr2020_hambox_bfbox/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2020/04/21/open_source_projects/" title="Our Open Source Projects" itemprop="url">Our Open Source Projects</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2020-04-21T08:06:31.000Z" itemprop="datePublished">Published 2020-04-21</time></p></header><div class="article-content"><p>基于身份保持的条件对抗生成网络的人脸老化IPCGAN (CVPR2018)<br><a href="https://github.com/dawei6875797/Face-Aging-with-Identity-Preserved-Conditional-Generative-Adversarial-Networks" target="_blank" rel="noopener">https://github.com/dawei6875797/Face-Aging-with-Identity-Preserved-Conditional-Generative-Adversarial-Networks</a><br>PyramidBox人脸检测器 (ECCV2018)<br><a href="https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/face_detection" target="_blank" rel="noopener">https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/face_detection</a><br>人脸检测轻量化模型faceboxes和blazeface<br><a href="https://github.com/PaddlePaddle/PaddleDetection/tree/release/0.2/configs/face_detection" target="_blank" rel="noopener">https://github.com/PaddlePaddle/PaddleDetection/tree/release/0.2/configs/face_detection</a><br>[抗击肺炎] 口罩人脸检测与分类<br><a href="https://www.paddlepaddle.org.cn/hub/scene/maskdetect" target="_blank" rel="noopener">https://www.paddlepaddle.org.cn/hub/scene/maskdetect</a></p><p class="article-more-link"></p></div><footer class="article-footer clearfix"><div class="article-catetags"><div class="article-tags"><span></span> <a href="/tags/Publications/">Publications</a></div></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2019/11/04/iccv2019-workshop-ppt/" title="Share our PPT about &#39;Delveing into High Performance Detector for Finding Tiny Faces&#39; on ICCV" itemprop="url">Share our PPT about &#39;Delveing into High Performance Detector for Finding Tiny Faces&#39; on ICCV</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2019-11-04T05:54:11.000Z" itemprop="datePublished">Published 2019-11-04</time></p></header><div class="article-content"><p>On 11.02.2019, we give a presentation on <a href="https://frchallenge.github.io/index" target="_blank" rel="noopener">ICCV 2019 Workshop<br>Face Recognition in the Wild</a>, and this is the slides.<br>Link:<br><a href="https://pan.baidu.com/s/13VuTE7U3tL2OzuNGsmaYJg" target="_blank" rel="noopener">Baidu Cloud</a><br><a href="https://drive.google.com/open?id=1fu8r2hs96ChrhlPDHeVzQneVH1zd-2m8" target="_blank" rel="noopener">Google Drive</a></p><p align="center"><img src="/imgs/iccv2019_workshop_ppt/ppt.jpg" hspace="10"><br></p><p class="article-more-link"><a href="/2019/11/04/iccv2019-workshop-ppt/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2019/10/27/wider_challenge_2019/" title="News:Our paper and code will be released in this page." itemprop="url">News:Our paper and code will be released in this page.</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2019-10-27T04:36:59.000Z" itemprop="datePublished">Published 2019-10-27</time></p></header><div class="article-content"><p>1st place and 1 invited talk in <a href="https://wider-challenge.org/2019.html" target="_blank" rel="noopener">face detection track on ICCV Wider Challenge 2019</a>.<br>More details, including tech report and code, will be introduced in this page.</p><p>TBD …</p><p align="center"><img src="/imgs/iccv2019_wider_challenge/leaderboard.jpg" hspace="10"><br>ICCV Wider Challenge优胜方案</p><p class="article-more-link"><a href="/2019/10/27/wider_challenge_2019/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"><div class="article-tags"><span></span> <a href="/tags/Challenge/">Challenge</a></div></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2019/09/04/tifs2019_daf/" title="News:1 paper accepted by TIFS2019" itemprop="url">News:1 paper accepted by TIFS2019</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2019-09-04T15:36:59.000Z" itemprop="datePublished">Published 2019-09-04</time></p></header><div class="article-content"><p>1 paper <a href="https://ieeexplore.ieee.org/document/8839888" target="_blank" rel="noopener">Progressively Refined Face Detection Through Semantics-Enriched Representation Learning</a> accepted by <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-information-forensics-and-security" target="_blank" rel="noopener">IEEE Transactions on Information Forensics and Security (TIFS)</a> — CCF A.</p><p align="center"><img src="/imgs/tifs2019_daf/architecture.jpg" hspace="10"><br></p><p class="article-more-link"><a href="/2019/09/04/tifs2019_daf/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"><div class="article-tags"><span></span> <a href="/tags/Publications/">Publications</a></div></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2019/08/04/iccv2019_wider_challenge/" title="News:1st place and 1 invited talk in face detection track on ICCV Wider Challenge 2019" itemprop="url">News:1st place and 1 invited talk in face detection track on ICCV Wider Challenge 2019</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2019-08-04T15:36:59.000Z" itemprop="datePublished">Published 2019-08-04</time></p></header><div class="article-content"><p>1st place and 1 invited talk in <a href="https://wider-challenge.org/2019.html" target="_blank" rel="noopener">face detection track on ICCV Wider Challenge 2019</a>. See you in Korea.</p><p align="center"><img src="/imgs/iccv2019_wider_challenge/leaderboard.jpg" hspace="10"><br>ICCV Wider Challenge优胜方案</p><p>This is the slides.<br><a href="https://pan.baidu.com/s/1QKUp4NZGK0nBZWzUqhBoVA" target="_blank" rel="noopener">Baidu Cloud</a><br>链接:<a href="https://pan.baidu.com/s/1QKUp4NZGK0nBZWzUqhBoVA" target="_blank" rel="noopener">https://pan.baidu.com/s/1QKUp4NZGK0nBZWzUqhBoVA</a> 密码:1hbx</p><p class="article-more-link"><a href="/2019/08/04/iccv2019_wider_challenge/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"><div class="article-tags"><span></span> <a href="/tags/Challenge/">Challenge</a></div></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2019/07/04/iccv2019_vot/" title="News:1st place and 1 invited talk in VOT-ST2019" itemprop="url">News:1st place and 1 invited talk in VOT-ST2019</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2019-07-04T15:36:59.000Z" itemprop="datePublished">Published 2019-07-04</time></p></header><div class="article-content"><p>1st place and 1 invited talk in <a href="http://www.votchallenge.net/vot2019/index.html" target="_blank" rel="noopener">VOT-ST2019</a>. See you in Korea.</p><p align="center"><img src="/imgs/iccv2019_vot/logo.jpg" hspace="10"><br>vot优胜方案</p><p>This is the slides.<br><a href="https://pan.baidu.com/s/1TghiaHtvbroNkRRaSlOEpg" target="_blank" rel="noopener">Baidu Cloud</a><br>链接:<a href="https://pan.baidu.com/s/1TghiaHtvbroNkRRaSlOEpg" target="_blank" rel="noopener">https://pan.baidu.com/s/1TghiaHtvbroNkRRaSlOEpg</a> 密码:6x0c</p><p class="article-more-link"><a href="/2019/07/04/iccv2019_vot/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"><div class="article-tags"><span></span> <a href="/tags/Challenge/">Challenge</a></div></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2019/04/04/arxiv2019_dubox/" title="News:1 paper submited to arxiv" itemprop="url">News:1 paper submited to arxiv</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2019-04-04T15:36:59.000Z" itemprop="datePublished">Published 2019-04-04</time></p></header><div class="article-content"><p><a href="https://arxiv.org/abs/1904.06883" target="_blank" rel="noopener">DuBox: No-Prior Box Objection Detection via Residual Dual Scale Detectors</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Traditional neural objection detection methods use multi-scale features that allow multiple detectors to perform<br>detecting tasks independently and in parallel. At the same time, with the handling of the prior box, the algorithm’s<br>ability to deal with scale invariance is enhanced. However, too many prior boxes and independent detectors will<br>increase the computational redundancy of the detection algorithm. In this study, we introduce Dubox, a new one-stage<br>approach that detects the objects without prior box. Working with multi-scale features, the designed dual scale residual unit makes dual scale detectors no longer run independently. The second scale detector learns the residual of the first. Dubox has enhanced the capacity of heuristic-guided that can further enable the first scale detector to maximize the detection of small targets and the second to detect objects that cannot be identified by the first one. Besides, for each scale detector, with the new classification-regression<br>progressive strapped loss makes our process not based on prior boxes. Integrating these strategies, our detection algorithm has achieved excellent performance in terms of speed and accuracy. Extensive experiments on the VOC, COCO object detection benchmark have confirmed the effectiveness of this algorithm.</p><p align="center"><img src="/imgs/arxiv2019_dubox/architecture.jpg" height="400" width="600" hspace="10"><br></p><p class="article-more-link"><a href="/2019/04/04/arxiv2019_dubox/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"><div class="article-tags"><span></span> <a href="/tags/Publications/">Publications</a></div></div><div class="comments-count"></div></footer></article><nav id="page-nav" class="clearfix"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next<span></span></a></nav></div><div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div><div id="asidepart"><div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div><aside class="clearfix"><div class="github-card"><p class="asidetitle">Github Card</p><div class="github-card" data-github="takecareofbigboss" data-theme="medium"></div><script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js"></script></div><div class="tagslist"><p class="asidetitle">Tags</p><ul class="clearfix"><li><a href="/tags/Publications/" title="Publications">Publications<sup>6</sup></a></li><li><a href="/tags/Challenge/" title="Challenge">Challenge<sup>3</sup></a></li><li><a href="/tags/Leaderboard/" title="Leaderboard">Leaderboard<sup>2</sup></a></li></ul></div><div class="linkslist"><p class="asidetitle">Links</p><ul><li><a href="https://scholar.google.com/citations?user=grP24aAAAAAJ&hl=zh-CN" target="_blank" title="Google Scholars">Google Scholars</a></li></ul></div><div class="rsspart"><a href="/atom.xml" target="_blank" title="rss">RSS</a></div><div class="weiboshow"><p class="asidetitle">Weibo</p><iframe width="100%" height="119" class="share_self" frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=&verifier=&dpc=1"></iframe></div></aside></div></div><footer><div id="footer"><div class="line"><span></span><div class="author"></div></div><section class="info"><p>Hello, I&#39;m Xu Tang in Baidu Research.<br>Major in face detection/ object tracking/ object detection/ ...</p></section><div class="social-font" class="clearfix"><a href="http://weibo.com/1842792965" target="_blank" class="icon-weibo" title="微博"></a> <a href="https://github.com/takecareofbigboss" target="_blank" class="icon-github" title="github"></a> <a href="https://www.linkedin.com/in/旭-汤-b12626ba" target="_blank" class="icon-linkedin" title="linkedin"></a> <a href="http://www.zhihu.com/people/tang-xu-60-83" target="_blank" class="icon-zhihu" title="知乎"></a> <a href="mailto:tangxu02@baidu.com" target="_blank" class="icon-email" title="Email Me"></a></div><p class="copyright">Powered by Xu Tang and Theme by Xu Tang © 2020 <a href="/about" target="_blank" title="Xu Tang&#39;s Homepages">Xu Tang&#39;s Homepages</a></p><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> <span class="post-meta-divider">|</span> <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span><p></p></div></footer><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><script src="/js/jquery.qrcode-0.12.0.min.js"></script><script type="text/javascript">$(document).ready(function(){$(".navbar").click(function(){$("header nav").toggleClass("shownav")});var e=0;var n=$("#main"),s=$("#asidepart"),a=$(".closeaside"),o=$(".openaside");a.click(function(){s.addClass("fadeOut").css("display","none"),o.css("display","block").addClass("fadeIn"),n.addClass("moveMain")}),o.click(function(){o.css("display","none").removeClass("beforeFadeIn"),s.css("display","block").removeClass("fadeOut").addClass("fadeIn"),n.removeClass("moveMain")}),$(window).scroll(function(){o.css("top",Math.max(80,260-$(this).scrollTop()))}),$(window).resize(function(){"number"==typeof window.innerWidth?e=window.innerWidth:document.documentElement&&document.documentElement.clientWidth&&(e=document.documentElement.clientWidth),1024<=e?$("header nav").removeClass("shownav"):(n.removeClass("moveMain"),s.css("display","block").removeClass("fadeOut"),o.css("display","none"))})})</script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">$(document).ready(function(){$(".article-content").each(function(a){$(this).find("img").each(function(){if(!$(this).parent().hasClass("fancybox")){var a=this.alt;a&&$(this).after('<span class="caption">'+a+"</span>"),$(this).wrap('<a href="'+this.src+'" title="'+a+'" class="fancybox"></a>')}}),$(this).find(".fancybox").each(function(){$(this).attr("rel","article"+a)})}),$.fancybox&&$(".fancybox").fancybox()})</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div id="totop"><a title="Back to Top"><img src="/img/scrollup.png"></a></div><script src="/js/totop.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body>