<!DOCTYPE HTML><html lang="zh-ch"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><title>Xu Tang&#39;s Homepages</title><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="author" content="Xu Tang&#39;s Homepages"><meta name="description" content="Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking"><meta property="og:type" content="website"><meta property="og:title" content="Xu Tang&#39;s Homepages"><meta property="og:url" content="http://tangxuvis.github.io/index.html"><meta property="og:site_name" content="Xu Tang&#39;s Homepages"><meta property="og:description" content="Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking"><meta property="og:locale" content="zh-ch"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Xu Tang&#39;s Homepages"><meta name="twitter:description" content="Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking"><link rel="alternative" href="/atom.xml" title="Xu Tang&#39;s Homepages" type="application/atom+xml"><link rel="icon" href="/img/favicon-32x32.ico"><link rel="apple-touch-icon" href="/img/jacman.jpg"><link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg"><link rel="stylesheet" href="/css/style.css"></head></html><body><header><div><div id="imglogo"><a href="/"><img src="/img/logo.png" alt="Xu Tang&#39;s Homepages" title="Xu Tang&#39;s Homepages"></a></div><div id="textlogo"><h1 class="site-name"><a href="/" title="Xu Tang&#39;s Homepages">Xu Tang&#39;s Homepages</a></h1><h2 class="blog-motto">Computer Vision &amp; Deep Learning &amp; Face Detection &amp; Object detection &amp; Object Tracking</h2></div><div class="navbar"><a class="navbutton navmobile" href="#" title="Menu"></a></div><nav class="animated"><ul><ul><li><a href="/">Home</a></li><li><a href="/archives">Archives</a></li><li><a href="/tags">Tags</a></li><li><a href="/resume">Resume</a></li><li><a href="/recruit">Recruit</a></li><li><a href="/about">About</a></li><li><form class="search" action="//google.com/search" method="get" accept-charset="utf-8"><label>Search</label> <input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search"> <input type="hidden" name="q" value="site:tangxuvis.github.io"></form></li></ul></ul></nav></div></header><div id="container"><div id="main"><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/07/10/aliyun_2021_vos_v1/" title="阿里巴巴全球视频云创新挑战赛发布视频人像分割数据集" itemprop="url">阿里巴巴全球视频云创新挑战赛发布视频人像分割数据集</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-07-10T06:54:11.000Z" itemprop="datePublished">Published 2021-07-10</time></p></header><div class="article-content"><p align="center"><img src="/imgs/alibaba/aliyun_vos_v3.jpg" hspace="10"><br></p><p>作为阿里摩酷实验室智能创作&amp;互动特效团队负责人，受邀担任阿里巴巴全球视频云创新挑战赛算法赛道评委，并且参与发布视频人像分割数据集。</p><p class="article-more-link"><a href="/2021/07/10/aliyun_2021_vos_v1/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/07/09/aliyun_2021_vos/" title="阿里巴巴全球视频云创新挑战赛评委" itemprop="url">阿里巴巴全球视频云创新挑战赛评委</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-07-09T06:54:11.000Z" itemprop="datePublished">Published 2021-07-09</time></p></header><div class="article-content"><p align="center"><img src="/imgs/alibaba/aliyun_vos_v1.jpg" hspace="10"><br></p><p align="center"><img src="/imgs/alibaba/aliyun_vos_v2.jpg" hspace="10"><br></p><p>受邀担任阿里巴巴全球视频云创新挑战赛算法赛道评委。</p><p class="article-more-link"><a href="/2021/07/09/aliyun_2021_vos/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/07/04/acmmm2021_v1/" title="News---paper accepted by ACMMM21: Decoupled IoU Regression for Object Detection" itemprop="url">News---paper accepted by ACMMM21: Decoupled IoU Regression for Object Detection</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-07-04T02:45:08.000Z" itemprop="datePublished">Published 2021-07-04</time></p></header><div class="article-content"><p>##Decoupled IoU Regression for Object Detection</p><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>Non-maximum suppression(NMS) is widely used in object detection pipelines for removing duplicated bounding boxes. The inconsistency between the confidence for NMS and the real localization confidence seriously affects detection performance. Prior works propose to predict Intersection-over-Union (IoU) between bounding boxes and corresponding ground-truths to improve NMS, while accurately predicting IoU is still a challenging problem. We argue that the complex definition of IoU and feature misalignment make it difficult to predict IoU accurately. In this paper, we propose a novel Decoupled IoU Regression(DIR) model to handle these problems. The proposed DIR decouples the traditional localization confidence metric IoU into two new metrics, Purity and Integrity. Purity reflects the proportion of the object area in the detected bounding box, and Integrity refers to the completeness of the detected object area. Separately predicting Purity and Integrity can divide the complex mapping between the bounding box and its IoU into two clearer mappings and model them independently. In addition, a simple but effective feature realignment approach is also introduced to make the IoU regressor work in a hindsight manner, which can make the target mapping more stable. The proposed DIR can be conveniently integrated with existing two-stage detectors and significantly improve their performance. Through a simple implementation of DIR with Faster R-CNN, we obtain 41.9% AP on MS COCO benchmark under ResNet101 backbone, which outperforms previous methods by a large margin and achieves state-of-the-art.</p><p class="article-more-link"><a href="/2021/07/04/acmmm2021_v1/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/07/04/acmmm2021/" title="News---paper accepted by ACMMM21: Deep Interactive Video Inpainting: an Invisibility Cloak for Harry Potter" itemprop="url">News---paper accepted by ACMMM21: Deep Interactive Video Inpainting: an Invisibility Cloak for Harry Potter</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-07-04T01:45:08.000Z" itemprop="datePublished">Published 2021-07-04</time></p></header><div class="article-content"><p>##Deep Interactive Video Inpainting: an Invisibility Cloak for Harry Potter</p><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>In this paper, we propose a new task of deep interactive video inpainting and an application for users interact with the machine. To our knowledge, this is the first deep learning based interactive video inpainting work that only uses a free form user input as guidance (i.e. scribbles) instead of mask annotations for each frame, which has academic, entertainment, and commercial value. With users’ scribbles on a certain frame, it can simultaneously perform interactive video object segmentation and video inpainting tasks throughout the whole video. We utilize a shared spatial-temporal memory module, which combines the interactive video object segmentation and video inpainting tasks into an end-to-end pipeline. In our framework, the past frames with object masks(either the user’s scribbles or the predicted masks) form an external memory, and the current frame as the query is segmented and inpainted using the information in the shared memory. Furthermore, our method allows users to iteratively refine the segmentation results, which can effectively improve the inpainting results where the video object segmentation fails, thus allowing users to obtain high-quality video inpainting results even on challenging sequences. Qualitative and quantitative experimental results demonstrate the superiority of our approach.</p><p class="article-more-link"><a href="/2021/07/04/acmmm2021/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/07/01/ai_interview_2021/" title="受邀AI科技评论专访：“我是一名AI视频up主，日更万部：这是我对人类世界的理解”" itemprop="url">受邀AI科技评论专访：“我是一名AI视频up主，日更万部：这是我对人类世界的理解”</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-07-01T06:54:11.000Z" itemprop="datePublished">Published 2021-07-01</time></p></header><div class="article-content"><p align="center"><img src="/imgs/alibaba/ali_media_ai.jpg" hspace="10"><br></p><p>受邀AI科技评论专访。，相关文章见链接:<a href="https://mp.weixin.qq.com/s/4KfOn7Aei2hhAf2HTU4oVA" target="_blank" rel="noopener">我是一名AI视频up主，日更万部：这是我对人类世界的理解</a></p><p align="center"><img src="/imgs/alibaba/ali_media_ai_v1.jpg" hspace="10"><br></p><p>阅读量过万。</p><p align="center"><img src="/imgs/alibaba/ali_media_ai_v2.jpg" hspace="10"><br></p><p class="article-more-link"><a href="/2021/07/01/ai_interview_2021/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/05/27/ali_sukan/" title="阿里文娱速看短视频自动化生产解决方案" itemprop="url">阿里文娱速看短视频自动化生产解决方案</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-05-27T06:54:11.000Z" itemprop="datePublished">Published 2021-05-27</time></p></header><div class="article-content"><p align="center"><img src="/imgs/alibaba/alibaba_sukan.jpg" hspace="10"><br></p><p><a href="https://mp.weixin.qq.com/s/rajmVlbWYl6jLjT_0Ztzaw" target="_blank" rel="noopener">阿里文娱速看短视频自动化生产解决方案</a></p><p>随着用户的时间碎片化程度加剧，视频“由长变短”成为一种趋势，信息流场景下的短视频消费需求日益增长，优酷每年为用户提供大量优质视频资源，具备天然的“由长变短”优势，并通过算法研究在速看短视频的自动化生产方面取得突破。</p><p>AI自动剪辑的目标是通过算法手段全自动或半自动进行视频剪辑，借助机器的批量化优势实现批量化生产，能够提升内容生产效率，提升短视频运营和分发效率。目前全网人工短视频生产集中在头部IP，AI自动剪辑可以为腰、尾部版权IP内容进行定向供货，带来新的流量增长点。</p><p>目前优酷已经将AI算法能力赋能到了多个业务场景，比如优酷弹幕看点提取、视频理解标签、剧集前情提要、智能封面图、视频速看解说等。例如，智能封面图能力不但支持短视频智能生产，还作为媒资的基础服务开放给UPGC，应用于优酷号上传、优酷搜索、短/小视频推荐等场景。</p><p>与此同时，还搭建了前情提要“机器生产+人工审核+广告生成”的生产链路，相比纯人工生产的前情提要，新链路将生产时长从天级别压缩到分钟级别，极大地提高了生产效率。</p><p class="article-more-link"><a href="/2021/05/27/ali_sukan/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/04/20/zheda_caideng_2021/" title="浙大蔡登老师实验室分享---视频多模态理解&amp;互动特效的研究与技术实践" itemprop="url">浙大蔡登老师实验室分享---视频多模态理解&amp;互动特效的研究与技术实践</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-04-20T06:54:11.000Z" itemprop="datePublished">Published 2021-04-20</time></p></header><div class="article-content"><p align="center"><img src="/imgs/alibaba/face_swap.jpg" hspace="10"><br></p><p align="center"><img src="/imgs/alibaba/face_attr.jpg" hspace="10"><br></p><p>浙大蔡登老师实验室分享—视频多模态理解&amp;互动特效的研究与技术实践，相关ppt参考链接：<a href="https://pan.baidu.com/s/1JkTfnyhT6HbsW53EYfyksg" target="_blank" rel="noopener">https://pan.baidu.com/s/1JkTfnyhT6HbsW53EYfyksg</a><br>提取密码：tgva （已报备）</p><p>链接: <a href="https://pan.baidu.com/s/1JkTfnyhT6HbsW53EYfyksg" target="_blank" rel="noopener">https://pan.baidu.com/s/1JkTfnyhT6HbsW53EYfyksg</a> 密码: tgva</p><p>分享内容包括：<br>人脸互动特效（换脸，人脸风格化、人脸编辑、人脸属性等）<br>视频浓缩，视频看点提取，视频解说等。</p><p class="article-more-link"><a href="/2021/04/20/zheda_caideng_2021/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2021/03/27/jieshuo_datafun_2021/" title="DataFun峰会知识图谱与智能创作论坛---阿里文娱视频智能生产技术实践" itemprop="url">DataFun峰会知识图谱与智能创作论坛---阿里文娱视频智能生产技术实践</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2021-03-27T06:54:11.000Z" itemprop="datePublished">Published 2021-03-27</time></p></header><div class="article-content"><p align="center"><img src="/imgs/datafun_2021/datafun.jpg" hspace="10"><br></p><p>DataFun峰会知识图谱与智能创作论坛技术分享，<a href="https://mp.weixin.qq.com/s/BmoCCLtUcZXAi23JEpQeaQ" target="_blank" rel="noopener">阿里文娱视频智能生产技术实践</a>。</p><p>分享我们在视频智能生产和创作上，近期的进展，包括视频切条、视频混剪&amp;二创、视频浓缩、视频解说、文本视频化等。</p><p>相关ppt见链接：<a href="https://pan.baidu.com/s/1KfPKhqIxk9sKGgj9FlmCVw" target="_blank" rel="noopener">https://pan.baidu.com/s/1KfPKhqIxk9sKGgj9FlmCVw</a><br>提取码：43C3 （已报备）</p><p class="article-more-link"><a href="/2021/03/27/jieshuo_datafun_2021/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2020/06/22/join-alibaba/" title="News:Join in Alibaba" itemprop="url">News:Join in Alibaba</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2020-06-22T06:54:11.000Z" itemprop="datePublished">Published 2020-06-22</time></p></header><div class="article-content"><p>很荣幸能够加入阿里巴巴，希望在接下来的几年能够继续努力、高效、快乐的工作，做出更多有意义、有价值、有影响力的科研成果和产品。<br>目前我在阿里文娱负责视频智能创作&amp;互动特效方向。现主要研究方向包含两大块—视频智能创作：Video Summary/ Video Grounding/ 视频智能解说/ 文本视频化/ Text Video Retrieval，人脸互动特效：人脸检测跟踪/人脸编辑/ 人脸风格化/人脸换脸/人脸属性等。</p><p align="center"><img src="/imgs/alibaba/alibaba.jpg" hspace="10"><br></p><p>另外，本人在招Research Intern和社招。欢迎感兴趣的同学可以邮件（或微信）联系我：<a href="mailto:buhui.tx@alibaba-inc.com" target="_blank" rel="noopener">buhui.tx@alibaba-inc.com</a><br>期待你的加入。</p><p class="article-more-link"><a href="/2020/06/22/join-alibaba/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><article class="post-expand post" itemprop="articleBody"><header class="article-info clearfix"><h1 itemprop="name"><a href="/2020/06/19/bytedance-talk/" title="字节跳动---人脸检测技术发展及小尺度人脸检测“框”实践" itemprop="url">字节跳动---人脸检测技术发展及小尺度人脸检测“框”实践</a></h1><p class="article-author">By <a href="/about" title="Xu Tang&#39;s Homepages" target="_blank" itemprop="author">Xu Tang&#39;s Homepages</a></p><p class="article-time"><time datetime="2020-06-19T06:54:11.000Z" itemprop="datePublished">Published 2020-06-19</time></p></header><div class="article-content"><p>荣幸受邀，在字节跳动分享了自己过往在人脸检测领域的成果和思考。</p><p align="center"><img src="/imgs/bytedance/bytedance.jpg" hspace="10"><br></p><p>相关资料参考链接：<a href="https://www.techbeat.net/talk-info?id=384" target="_blank" rel="noopener">techbeat官网链接</a></p><p class="article-more-link"><a href="/2020/06/19/bytedance-talk/#more">Read More</a></p></div><footer class="article-footer clearfix"><div class="article-catetags"></div><div class="comments-count"></div></footer></article><nav id="page-nav" class="clearfix"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next<span></span></a></nav></div><div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div><div id="asidepart"><div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div><aside class="clearfix"><div class="github-card"><p class="asidetitle">Github Card</p><div class="github-card" data-github="takecareofbigboss" data-theme="medium"></div><script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js"></script></div><div class="tagslist"><p class="asidetitle">Tags</p><ul class="clearfix"><li><a href="/tags/Publications/" title="Publications">Publications<sup>6</sup></a></li><li><a href="/tags/Challenge/" title="Challenge">Challenge<sup>4</sup></a></li><li><a href="/tags/Leaderboard/" title="Leaderboard">Leaderboard<sup>2</sup></a></li></ul></div><div class="linkslist"><p class="asidetitle">Links</p><ul><li><a href="https://scholar.google.com/citations?user=grP24aAAAAAJ&hl=zh-CN" target="_blank" title="Google Scholars">Google Scholars</a></li></ul></div><div class="rsspart"><a href="/atom.xml" target="_blank" title="rss">RSS</a></div><div class="weiboshow"><p class="asidetitle">Weibo</p><iframe width="100%" height="119" class="share_self" frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=&verifier=&dpc=1"></iframe></div></aside></div></div><footer><div id="footer"><div class="line"><span></span><div class="author"></div></div><section class="info"><p>Hello, I&#39;m Xu Tang in Baidu Research.<br>Major in face detection/ object tracking/ object detection/ ...</p></section><div class="social-font" class="clearfix"><a href="http://weibo.com/1842792965" target="_blank" class="icon-weibo" title="微博"></a> <a href="https://github.com/takecareofbigboss" target="_blank" class="icon-github" title="github"></a> <a href="https://www.linkedin.com/in/旭-汤-b12626ba" target="_blank" class="icon-linkedin" title="linkedin"></a> <a href="http://www.zhihu.com/people/tang-xu-60-83" target="_blank" class="icon-zhihu" title="知乎"></a> <a href="mailto:tangxu02@baidu.com" target="_blank" class="icon-email" title="Email Me"></a></div><p class="copyright">Powered by Xu Tang and Theme by Xu Tang © 2021 <a href="/about" target="_blank" title="Xu Tang&#39;s Homepages">Xu Tang&#39;s Homepages</a></p><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> <span class="post-meta-divider">|</span> <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span><p></p></div></footer><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><script src="/js/jquery.qrcode-0.12.0.min.js"></script><script type="text/javascript">$(document).ready(function(){$(".navbar").click(function(){$("header nav").toggleClass("shownav")});var e=0;var n=$("#main"),s=$("#asidepart"),a=$(".closeaside"),o=$(".openaside");a.click(function(){s.addClass("fadeOut").css("display","none"),o.css("display","block").addClass("fadeIn"),n.addClass("moveMain")}),o.click(function(){o.css("display","none").removeClass("beforeFadeIn"),s.css("display","block").removeClass("fadeOut").addClass("fadeIn"),n.removeClass("moveMain")}),$(window).scroll(function(){o.css("top",Math.max(80,260-$(this).scrollTop()))}),$(window).resize(function(){"number"==typeof window.innerWidth?e=window.innerWidth:document.documentElement&&document.documentElement.clientWidth&&(e=document.documentElement.clientWidth),1024<=e?$("header nav").removeClass("shownav"):(n.removeClass("moveMain"),s.css("display","block").removeClass("fadeOut"),o.css("display","none"))})})</script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">$(document).ready(function(){$(".article-content").each(function(a){$(this).find("img").each(function(){if(!$(this).parent().hasClass("fancybox")){var a=this.alt;a&&$(this).after('<span class="caption">'+a+"</span>"),$(this).wrap('<a href="'+this.src+'" title="'+a+'" class="fancybox"></a>')}}),$(this).find(".fancybox").each(function(){$(this).attr("rel","article"+a)})}),$.fancybox&&$(".fancybox").fancybox()})</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div id="totop"><a title="Back to Top"><img src="/img/scrollup.png"></a></div><script src="/js/totop.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body>